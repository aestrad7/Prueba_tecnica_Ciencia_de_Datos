{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81412, 29), (20354, 29))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Dividir los datos en características (X) y variable objetivo (y)\n",
    "X = data.drop('readmitted', axis=1)\n",
    "y = data['readmitted']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Verificar las dimensiones de los conjuntos de datos\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readmitted\n",
       "0    72326\n",
       "1    72326\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar el conjunto de entrenamiento por clases\n",
    "X_train_majority = X_train[y_train == 0]\n",
    "X_train_minority = X_train[y_train == 1]\n",
    "y_train_majority = y_train[y_train == 0]\n",
    "y_train_minority = y_train[y_train == 1]\n",
    "\n",
    "# Realizar el sobremuestreo\n",
    "X_train_minority_oversampled = X_train_minority.sample(len(X_train_majority), replace=True, random_state=42)\n",
    "y_train_minority_oversampled = y_train_minority.sample(len(y_train_majority), replace=True, random_state=42)\n",
    "\n",
    "# Combinar las clases mayoritarias y minoritarias sobremuestreadas\n",
    "X_train_oversampled = pd.concat([X_train_majority, X_train_minority_oversampled])\n",
    "y_train_oversampled = pd.concat([y_train_majority, y_train_minority_oversampled])\n",
    "\n",
    "# Verificar el equilibrio de las clases después del sobremuestreo\n",
    "y_train_oversampled.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imputar valores faltantes con la mediana\n",
    "median_value = X_train['time_in_hospital'].median()\n",
    "X_train['time_in_hospital'].fillna(median_value, inplace=True)\n",
    "X_test['time_in_hospital'].fillna(median_value, inplace=True)\n",
    "\n",
    "# Verificar si aún hay valores faltantes\n",
    "missing_values_after = X_train.isnull().sum().sum()\n",
    "missing_values_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'median_time_in_hospital.pkl'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Guardar la mediana en un archivo pickle\n",
    "pickle_filename = \"median_time_in_hospital.pkl\"\n",
    "with open(pickle_filename, 'wb') as file:\n",
    "    pickle.dump(median_value, file)\n",
    "\n",
    "pickle_filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anestrada/opt/anaconda3/envs/Prueba_tecnica_MeLi_2023/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anestrada/opt/anaconda3/envs/Prueba_tecnica_MeLi_2023/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anestrada/opt/anaconda3/envs/Prueba_tecnica_MeLi_2023/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     18083\n",
      "           1       0.00      0.00      0.00      2271\n",
      "\n",
      "    accuracy                           0.89     20354\n",
      "   macro avg       0.44      0.50      0.47     20354\n",
      "weighted avg       0.79      0.89      0.84     20354\n",
      "\n",
      "[[18083     0]\n",
      " [ 2271     0]]\n",
      "------------------------------------------------------------\n",
      "Evaluating model: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     18083\n",
      "           1       0.60      0.02      0.03      2271\n",
      "\n",
      "    accuracy                           0.89     20354\n",
      "   macro avg       0.74      0.51      0.49     20354\n",
      "weighted avg       0.86      0.89      0.84     20354\n",
      "\n",
      "[[18059    24]\n",
      " [ 2235    36]]\n",
      "------------------------------------------------------------\n",
      "Evaluating model: SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anestrada/opt/anaconda3/envs/Prueba_tecnica_MeLi_2023/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anestrada/opt/anaconda3/envs/Prueba_tecnica_MeLi_2023/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/anestrada/opt/anaconda3/envs/Prueba_tecnica_MeLi_2023/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94     18083\n",
      "           1       0.00      0.00      0.00      2271\n",
      "\n",
      "    accuracy                           0.89     20354\n",
      "   macro avg       0.44      0.50      0.47     20354\n",
      "weighted avg       0.79      0.89      0.84     20354\n",
      "\n",
      "[[18083     0]\n",
      " [ 2271     0]]\n",
      "------------------------------------------------------------\n",
      "Evaluating model: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     18083\n",
      "           1       0.49      0.04      0.07      2271\n",
      "\n",
      "    accuracy                           0.89     20354\n",
      "   macro avg       0.69      0.52      0.51     20354\n",
      "weighted avg       0.85      0.89      0.84     20354\n",
      "\n",
      "[[17989    94]\n",
      " [ 2182    89]]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"SVM\": SVC(),\n",
    "    \"XGBoost\": xgb.XGBClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating model: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: XGBoost\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.055 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.051 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.053 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.056 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.041 total time=   5.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.053 total time=   6.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.045 total time=   6.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.044 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.052 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=7, min_child_weight=1, n_estimators=50, subsample=1.0;, score=0.058 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.010 total time=   6.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.005 total time=   6.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.005 total time=   6.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.008 total time=   6.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.014 total time=   6.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.048 total time=   6.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.048 total time=   6.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.7;, score=0.010 total time=  11.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.7;, score=0.020 total time=  11.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.7;, score=0.018 total time=  11.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.7;, score=0.011 total time=  11.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.7;, score=0.011 total time=  11.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.036 total time=   5.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.037 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=10, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.049 total time=   5.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, subsample=1.0;, score=0.067 total time=  21.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, subsample=1.0;, score=0.055 total time=  22.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, subsample=1.0;, score=0.061 total time=  22.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, subsample=1.0;, score=0.061 total time=  22.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=10, min_child_weight=1, n_estimators=500, subsample=1.0;, score=0.058 total time=  23.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.013 total time=  12.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.013 total time=  12.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.016 total time=  12.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.021 total time=  12.4s\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.8;, score=0.007 total time=  11.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.9;, score=0.014 total time=  12.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.8;, score=0.017 total time=  12.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.9;, score=0.068 total time=   5.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.9;, score=0.059 total time=   5.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.9;, score=0.055 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.9;, score=0.064 total time=   6.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=0.9;, score=0.065 total time=   6.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.8;, score=0.014 total time=  14.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.8;, score=0.011 total time=  14.8s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.4, learning_rate=0.01, max_depth=5, min_child_weight=10, n_estimators=500, subsample=0.8;, score=0.015 total time=  15.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=50, subsample=0.8;, score=0.000 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=50, subsample=0.8;, score=0.000 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=50, subsample=0.8;, score=0.000 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=50, subsample=0.8;, score=0.000 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, subsample=1.0;, score=0.057 total time=  14.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, subsample=1.0;, score=0.070 total time=  15.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, subsample=1.0;, score=0.068 total time=  14.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, subsample=1.0;, score=0.074 total time=  14.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=50, subsample=0.8;, score=0.000 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.049 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.051 total time=   4.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.038 total time=   4.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.039 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.048 total time=   4.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.082 total time=  25.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, min_child_weight=5, n_estimators=500, subsample=1.0;, score=0.073 total time=  13.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.092 total time=  25.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.072 total time=  25.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.063 total time=  25.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=10, min_child_weight=5, n_estimators=500, subsample=0.7;, score=0.076 total time=  24.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.036 total time=   5.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.038 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.049 total time=   5.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.043 total time=   5.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.056 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=10, min_child_weight=10, n_estimators=100, subsample=1.0;, score=0.049 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.053 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.009 total time=  11.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.038 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.047 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=5, n_estimators=100, subsample=0.9;, score=0.049 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.015 total time=  11.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.012 total time=  11.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.013 total time=  11.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=200, subsample=0.7;, score=0.010 total time=  11.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.8;, score=0.061 total time=   5.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.8;, score=0.049 total time=   5.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.8;, score=0.053 total time=   5.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.061 total time=   8.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.055 total time=   8.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.059 total time=   8.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.8;, score=0.047 total time=   5.5s\n",
      "[CV 5/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.067 total time=   8.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, gamma=0.2, learning_rate=0.1, max_depth=10, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.059 total time=   8.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.8;, score=0.067 total time=   5.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=50, subsample=0.8;, score=0.000 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.059 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=50, subsample=0.8;, score=0.000 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.004 total time=   6.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.057 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=50, subsample=0.8;, score=0.001 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.010 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.051 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.059 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.2, max_depth=5, min_child_weight=1, n_estimators=200, subsample=1.0;, score=0.056 total time=   3.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=50, subsample=0.8;, score=0.000 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=3, min_child_weight=5, n_estimators=50, subsample=0.8;, score=0.000 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.010 total time=   6.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.007 total time=   6.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=7, min_child_weight=10, n_estimators=200, subsample=0.7;, score=0.005 total time=   6.2s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Definición de la grilla de hiperparámetros para XGBoost\n",
    "xgb_param_grid = {\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200, 500],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.4],\n",
    "    'min_child_weight': [1, 5, 10]\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"XGBoost\": xgb.XGBClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Evaluating model: {name}\")\n",
    "    \n",
    "    if name == \"XGBoost\":  # Si el modelo es XGBoost, hacemos el tuning\n",
    "        search = RandomizedSearchCV(model, param_distributions=xgb_param_grid, n_iter=50, scoring='f1', n_jobs=-1, cv=5, verbose=3)\n",
    "        search.fit(X_train, y_train)\n",
    "        best_model = search.best_estimator_  # Usamos el mejor modelo encontrado\n",
    "    else:\n",
    "        best_model = model\n",
    "        best_model.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data (replace with your data)\n",
    "X_train, y_train = X_train, y_train\n",
    "\n",
    "# Initialize and train the XGBoost model with the best hyperparameters\n",
    "model = xgb.XGBClassifier(\n",
    "    colsample_bytree=0.7, \n",
    "    gamma=0.2, \n",
    "    learning_rate=0.05, \n",
    "    max_depth=3, \n",
    "    min_child_weight=5, \n",
    "    n_estimators=100, \n",
    "    subsample=1.0\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, \"best_xgboost_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Prueba_tecnica_MeLi_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
